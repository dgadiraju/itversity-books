{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development life cycle and advanced queries – Scala and HBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of this session we will see how Scala based applications can be developed to load data into HBase tables along with some advanced concepts of HBase.\n",
    "\n",
    "* Data Modeling\n",
    "* Develop Scala application to load data into HBase tables – Thin Schema\n",
    "* Develop Scala application to load data into HBase tables – Thick Schema\n",
    "* Overview of HBase filters\n",
    "\n",
    "### Data Modeling\n",
    "In HBase tables are typically denormalized. For regular applications we should be able to either partial scans or get to get the data. Depending up on the requirement we need to decide on data model.\n",
    "\n",
    "* Thin Schema vs. Thick Schema\n",
    "* Deciding on Row Key\n",
    "* Deciding on Column families\n",
    "* In case of Thick Schema, we should come up with column name where we can leverage filtering data on column name range\n",
    "\n",
    "### Develop Application – Thin Schema\n",
    "As part of this program we will see how we can read data from a file and load data into nyse:stock_data_thin using Scala as programming language using HBase APIs.\n",
    "\n",
    "* Read data from file (we will only process one file at a time)\n",
    "* Create HBase Connection\n",
    "* Create table object for nyse:stock_data_thin\n",
    "* For each record build put object and load into HBase table using table object (for performance reasons we can add multiple rows together)\n",
    "* We will also see how to add main class as part of assembly, reassemble the fat jar and run it on the cluster (use sbt assembly)\n",
    "* Combination of date and stock ticker is row key. Every row in this table will end up having 7 fields.\n",
    "* If your application requirement is to get trade details for a given stock for a given day this is the best design."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "// HBaseDemo-01-NYSELoad-thin-build.sbt\n",
    "\n",
    "name := \"HBaseDemo\"\n",
    "\n",
    "version := \"0.1\"\n",
    "\n",
    "scalaVersion := \"2.11.12\"\n",
    "\n",
    "libraryDependencies += \"com.typesafe\" % \"config\" % \"1.3.2\"\n",
    "libraryDependencies += \"org.apache.hadoop\" % \"hadoop-common\" % \"2.7.0\"\n",
    "libraryDependencies += \"org.apache.hbase\" % \"hbase-client\" % \"1.1.2\"\n",
    "libraryDependencies += \"org.apache.hbase\" % \"hbase-common\" % \"1.1.2\"\n",
    "\n",
    "assemblyMergeStrategy in assembly := {\n",
    "  case m if m.toLowerCase.endsWith(\"manifest.mf\") => MergeStrategy.discard\n",
    "  case m if m.startsWith(\"META-INF\") => MergeStrategy.discard\n",
    "  case PathList(\"javax\", \"servlet\", xs@_*) => MergeStrategy.first\n",
    "  case PathList(\"org\", \"apache\", xs@_*) => MergeStrategy.first\n",
    "  case \"about.html\" => MergeStrategy.rename\n",
    "  case \"reference.conf\" => MergeStrategy.concat\n",
    "  case _ => MergeStrategy.first\n",
    "}\n",
    "\n",
    "mainClass in assembly := Some(\"NYSELoad\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# HBaseDemo-02-thin-NYSELoad.scala\n",
    "\n",
    "import org.apache.hadoop.hbase.{HBaseConfiguration, TableName}\n",
    "import org.apache.hadoop.hbase.client.{Connection, ConnectionFactory, Put, Table}\n",
    "import org.apache.hadoop.hbase.util.Bytes\n",
    "import com.typesafe.config.{Config, ConfigFactory}\n",
    "import org.apache.hadoop.conf.Configuration\n",
    "\n",
    "import scala.io.Source\n",
    "\n",
    "/**\n",
    "  * Created by itversity on 27/08/18.\n",
    "  */\n",
    "object NYSELoad {\n",
    "\n",
    "  def getHbaseConnection(conf: Config, env: String): Connection ={\n",
    "    //Create Hbase Configuration Object\n",
    "    val hbaseConfig: Configuration = HBaseConfiguration.create()\n",
    "    hbaseConfig.set(\"hbase.zookeeper.quorum\",\n",
    "      conf.getString(\"zookeeper.quorum\"))\n",
    "    hbaseConfig.set(\"hbase.zookeeper.property.clientPort\",\n",
    "      conf.getString(\"zookeeper.port\"))\n",
    "    if(env != \"dev\") {\n",
    "      hbaseConfig.set(\"zookeeper.znode.parent\", \"/hbase-unsecure\")\n",
    "      hbaseConfig.set(\"hbase.cluster.distributed\", \"true\")\n",
    "    }\n",
    "    val connection = ConnectionFactory.createConnection(hbaseConfig)\n",
    "    connection\n",
    "  }\n",
    "\n",
    "  def buildPutList(table: Table, nyseRecord: String, schemaType: String) = {\n",
    "    val nyseAttributes = nyseRecord.split(\",\")\n",
    "    val put = schemaType match {\n",
    "      case \"thin\" => {\n",
    "        val put = new Put(Bytes.toBytes(\n",
    "          nyseAttributes(1) + \":\" +\n",
    "            nyseAttributes(0)))\n",
    "        // Key\n",
    "        put.addColumn(Bytes.toBytes(\"sd\"),\n",
    "          Bytes.toBytes(\"op\"),\n",
    "          Bytes.toBytes(nyseAttributes(2)))\n",
    "        put.addColumn(Bytes.toBytes(\"sd\"),\n",
    "          Bytes.toBytes(\"hp\"),\n",
    "          Bytes.toBytes(nyseAttributes(3)))\n",
    "        put.addColumn(Bytes.toBytes(\"sd\"),\n",
    "          Bytes.toBytes(\"lp\"),\n",
    "          Bytes.toBytes(nyseAttributes(4)))\n",
    "        put.addColumn(Bytes.toBytes(\"sd\"),\n",
    "          Bytes.toBytes(\"cp\"),\n",
    "          Bytes.toBytes(nyseAttributes(5)))\n",
    "        put.addColumn(Bytes.toBytes(\"sd\"),\n",
    "          Bytes.toBytes(\"v\"),\n",
    "          Bytes.toBytes(nyseAttributes(6)))\n",
    "        put\n",
    "      }\n",
    "    }\n",
    "    put\n",
    "  }\n",
    "\n",
    "  def readFilesAndLoad(table: Table, nysePath: String, schemaType: String): Unit = {\n",
    "    val nyseData = Source.fromFile(nysePath).getLines()\n",
    "    nyseData.foreach(record => {\n",
    "      val row = buildPutList(table, record, schemaType)\n",
    "      table.put(row)\n",
    "    })\n",
    "  }\n",
    "\n",
    "  def main(args: Array[String]): Unit = {\n",
    "    val env = args(0)\n",
    "    val conf = ConfigFactory.load.getConfig(env)\n",
    "    val connection = getHbaseConnection(conf, env)\n",
    "    val table = connection.\n",
    "      getTable(TableName.valueOf(args(2)))\n",
    "    val schemaType = args(3)\n",
    "\n",
    "    readFilesAndLoad(table, args(1), schemaType)\n",
    "\n",
    "    table.close\n",
    "    connection.close\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# HBaseDemo-03-thin-NYSELoad.sh\n",
    "\n",
    "# Make sure hbase table is created\n",
    "# create 'nyse:stock_data_thin', 'sd'\n",
    "\n",
    "java -jar \\\n",
    "  target/scala-2.11/HBaseDemo-assembly-0.1.jar \\\n",
    "  prod /data/nyse/NYSE_2016.txt nyse:stock_data_thin thin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop Application – Thick Schema\n",
    "As part of this program we will see how we can read data from a file and load data into nyse:stock_data_thin using Scala as programming language using HBase APIs.\n",
    "\n",
    "* Read data from file (we will only process one file at a time)\n",
    "* Create HBase Connection\n",
    "* Create table object for nyse:stock_data_thin\n",
    "* For each record build put object and load into HBase table using table object (for performance reasons we can add multiple rows together)\n",
    "* We will also see how to add main class as part of assembly, reassemble the fat jar and run it on the cluster (use sbt assembly)\n",
    "* Combination of month and stock ticker is used as row key. With in each row, combination of date and stock ticker is used as column name.\n",
    "* On average each row (month and stock ticker) will contain 210 columns.\n",
    "* If your requirement is to perform moving transformations, this design will perform better."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# HBaseDemo-02-thick-NYSELoad.scala\n",
    "\n",
    "import org.apache.hadoop.hbase.{HBaseConfiguration, TableName}\n",
    "import org.apache.hadoop.hbase.client.{Connection, ConnectionFactory, Put, Table}\n",
    "import org.apache.hadoop.hbase.util.Bytes\n",
    "import com.typesafe.config.{Config, ConfigFactory}\n",
    "import org.apache.hadoop.conf.Configuration\n",
    "\n",
    "import scala.io.Source\n",
    "\n",
    "/**\n",
    "  * Created by itversity on 27/08/18.\n",
    "  */\n",
    "object NYSELoad {\n",
    "\n",
    "  def getHbaseConnection(conf: Config, env: String): Connection ={\n",
    "    //Create Hbase Configuration Object\n",
    "    val hbaseConfig: Configuration = HBaseConfiguration.create()\n",
    "    hbaseConfig.set(\"hbase.zookeeper.quorum\",\n",
    "      conf.getString(\"zookeeper.quorum\"))\n",
    "    hbaseConfig.set(\"hbase.zookeeper.property.clientPort\",\n",
    "      conf.getString(\"zookeeper.port\"))\n",
    "    if(env != \"dev\") {\n",
    "      hbaseConfig.set(\"zookeeper.znode.parent\", \"/hbase-unsecure\")\n",
    "      hbaseConfig.set(\"hbase.cluster.distributed\", \"true\")\n",
    "    }\n",
    "    val connection = ConnectionFactory.createConnection(hbaseConfig)\n",
    "    connection\n",
    "  }\n",
    "\n",
    "  def buildPutList(table: Table, nyseRecord: String, schemaType: String) = {\n",
    "    val nyseAttributes = nyseRecord.split(\",\")\n",
    "    val put = schemaType match {\n",
    "      case \"thin\" => {\n",
    "        val put = new Put(Bytes.toBytes(\n",
    "          nyseAttributes(1) + \":\" +\n",
    "            nyseAttributes(0)))\n",
    "        // Key\n",
    "        put.addColumn(Bytes.toBytes(\"sd\"),\n",
    "          Bytes.toBytes(\"op\"),\n",
    "          Bytes.toBytes(nyseAttributes(2)))\n",
    "        put.addColumn(Bytes.toBytes(\"sd\"),\n",
    "          Bytes.toBytes(\"hp\"),\n",
    "          Bytes.toBytes(nyseAttributes(3)))\n",
    "        put.addColumn(Bytes.toBytes(\"sd\"),\n",
    "          Bytes.toBytes(\"lp\"),\n",
    "          Bytes.toBytes(nyseAttributes(4)))\n",
    "        put.addColumn(Bytes.toBytes(\"sd\"),\n",
    "          Bytes.toBytes(\"cp\"),\n",
    "          Bytes.toBytes(nyseAttributes(5)))\n",
    "        put.addColumn(Bytes.toBytes(\"sd\"),\n",
    "          Bytes.toBytes(\"v\"),\n",
    "          Bytes.toBytes(nyseAttributes(6)))\n",
    "        put\n",
    "      }\n",
    "      case \"thick\" => {\n",
    "        val put = new Put(Bytes.toBytes(\n",
    "          nyseAttributes(1).substring(0, 6) + \":\" +\n",
    "            nyseAttributes(0)))\n",
    "        // Key\n",
    "        put.addColumn(Bytes.toBytes(\"sd\"),\n",
    "          Bytes.toBytes(nyseAttributes(1) + \",\" + \"op\"),\n",
    "          Bytes.toBytes(nyseAttributes(2)))\n",
    "        put.addColumn(Bytes.toBytes(\"sd\"),\n",
    "          Bytes.toBytes(nyseAttributes(1) + \",\" + \"hp\"),\n",
    "          Bytes.toBytes(nyseAttributes(3)))\n",
    "        put.addColumn(Bytes.toBytes(\"sd\"),\n",
    "          Bytes.toBytes(nyseAttributes(1) + \",\" + \"lp\"),\n",
    "          Bytes.toBytes(nyseAttributes(4)))\n",
    "        put.addColumn(Bytes.toBytes(\"sd\"),\n",
    "          Bytes.toBytes(nyseAttributes(1) + \",\" + \"cp\"),\n",
    "          Bytes.toBytes(nyseAttributes(5)))\n",
    "        put.addColumn(Bytes.toBytes(\"sd\"),\n",
    "          Bytes.toBytes(nyseAttributes(1) + \",\" + \"v\"),\n",
    "          Bytes.toBytes(nyseAttributes(6)))\n",
    "        put\n",
    "      }\n",
    "    }\n",
    "    put\n",
    "  }\n",
    "\n",
    "  def readFilesAndLoad(table: Table, nysePath: String, schemaType: String): Unit = {\n",
    "    val nyseData = Source.fromFile(nysePath).getLines()\n",
    "    nyseData.foreach(record => {\n",
    "      val row = buildPutList(table, record, schemaType)\n",
    "      table.put(row)\n",
    "    })\n",
    "  }\n",
    "\n",
    "  def main(args: Array[String]): Unit = {\n",
    "    val env = args(0)\n",
    "    val conf = ConfigFactory.load.getConfig(env)\n",
    "    val connection = getHbaseConnection(conf, env)\n",
    "    val table = connection.\n",
    "      getTable(TableName.valueOf(args(2)))\n",
    "    val schemaType = args(3)\n",
    "\n",
    "    readFilesAndLoad(table, args(1), schemaType)\n",
    "\n",
    "    table.close\n",
    "    connection.close\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# HBaseDemo-03-thick-NYSELoad.sh\n",
    "\n",
    "# Make sure hbase table is created\n",
    "# create 'nyse:stock_data_thick', 'sd'\n",
    "\n",
    "java -jar \\\n",
    "  target/scala-2.11/HBaseDemo-assembly-0.1.jar \\\n",
    "  prod /data/nyse/NYSE_2016.txt nyse:stock_data_thick thick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of HBase filters\n",
    "Let us deep dive into advanced querying capabilities using HBase shell.\n",
    "\n",
    "* We can limit number of rows as part of scan and number of cells as part of get (using limit)\n",
    "* We can perform partial scan using startrow and endrow\n",
    "* We can project the desired fields as part of scan\n",
    "* There are bunch of filters available to query the data\n",
    "* Some filters are available as part of scan, some of them are available as part of get, while some of them are applicable to both scan as well as get."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# HBaseDemo-filters.sh\n",
    "\n",
    "count 'nyse:stock_data_thick'\n",
    "\n",
    "# To get first 10 records\n",
    "scan 'nyse:stock_data_thick', \n",
    "{LIMIT => 10}\n",
    "\n",
    "# Partial Scan example (using STARTROW and ENDROW)\n",
    "scan 'nyse:stock_data_thick', \n",
    "{STARTROW => '201601:A', ENDROW => '201601:B'}\n",
    "\n",
    "# Get all rows with prefix\n",
    "# To get all the rows which have prefix 200401\n",
    "# This filter is not available on get (we have ColumnPrefixFilter)\n",
    "scan 'nyse:stock_data_thick', \n",
    "{FILTER => \"PrefixFilter('201601')\", LIMIT => 10}\n",
    "\n",
    "# Using partial scan with STARTROW/ENDROW will perform better\n",
    "scan 'nyse:stock_data_thick', \n",
    "{FILTER => \"PrefixFilter('201601')\", \n",
    " LIMIT => 10, \n",
    " STARTROW => '201601:A', \n",
    " ENDROW => '201601:ZZZZ'\n",
    "}\n",
    "\n",
    "# Projecting required columns using COLUMNS\n",
    "scan 'nyse:stock_data_thick', \n",
    "{COLUMNS => ['sd:20160129,lp', 'sd:20160129,hp'], LIMIT => 10}\n",
    "\n",
    "# Using partial scan with STARTROW/ENDROW will perform better\n",
    "scan 'nyse:stock_data_thick', \n",
    "{COLUMNS => ['sd:20160129,lp', 'sd:20160129,hp'], \n",
    " LIMIT => 10, \n",
    " STARTROW => '201601:A', \n",
    " ENDROW => '201601:ZZZZ'\n",
    "}\n",
    "\n",
    "get 'nyse:stock_data_thick', '201601:A', \n",
    "{COLUMNS => ['sd:20160129,lp', 'sd:20160129,hp'], LIMIT => 10}\n",
    "\n",
    "# Projecting required columns using column prefix\n",
    "# We can either use ColumnPrefixFilter or MultipleColumnPrefixFilter\n",
    "scan 'nyse:stock_data_thick', \n",
    "{FILTER => \"ColumnPrefixFilter('20160129')\", LIMIT => 10}\n",
    "\n",
    "# Using partial scan with STARTROW/ENDROW and then ColumnPrefixFilter will perform better in this case\n",
    "scan 'nyse:stock_data_thick', \n",
    "{FILTER => \"ColumnPrefixFilter('20160129')\", \n",
    " STARTROW => '201601:A', \n",
    " ENDROW => '201601:ZZZZ', \n",
    " LIMIT => 10\n",
    "}\n",
    "\n",
    "get 'nyse:stock_data_thick', '201601:A', \n",
    "{FILTER => \"ColumnPrefixFilter('20160129')\"}\n",
    "get 'nyse:stock_data_thick', '201601:A', \n",
    "{FILTER => \"MultipleColumnPrefixFilter('20160129', '20160128')\"}\n",
    "\n",
    "# Projecting required columns using range\n",
    "# To get all the rows from 20040110 to 20040115\n",
    "scan 'nyse:stock_data_thick', \n",
    "{FILTER => \"ColumnRangeFilter('20160125,cp', true, '20160129,v', true)\", \n",
    " LIMIT => 10\n",
    "}\n",
    "\n",
    "# Using partial scan with STARTROW/ENDROW and then ColumnRangeFilter will perform better in this case\n",
    "scan 'nyse:stock_data_thick', \n",
    "{FILTER => \"ColumnRangeFilter('20160125,cp', true, '20160129,v', true)\", \n",
    " LIMIT => 10, \n",
    " STARTROW => '201601:A', \n",
    " ENDROW => '201601:ZZZZ'\n",
    "}\n",
    "\n",
    "get 'nyse:stock_data_thick', '201601:A', \n",
    "{FILTER => \"ColumnRangeFilter('20160125,cp', true, '20160129,v', true)\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sample program using filter"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# HBaseDemo-ColumnPrefixFilter-example.scala\n",
    "\n",
    "import org.apache.hadoop.conf.Configuration\n",
    "import org.apache.hadoop.hbase.client._\n",
    "import org.apache.hadoop.hbase.{CellUtil, HBaseConfiguration, TableName}\n",
    "import org.apache.hadoop.hbase.util.Bytes\n",
    "import org.apache.hadoop.hbase.filter.ColumnPrefixFilter\n",
    "\n",
    "val hbaseConf = HBaseConfiguration.create()\n",
    "hbaseConf.set(\"hbase.zookeeper.quorum\", \"nn01.itversity.com,nn02.itversity.com,rm01.itversity.com\")\n",
    "hbaseConf.set(\"hbase.zookeeper.property.clientPort\", \"2181\")\n",
    "hbaseConf.set(\"zookeeper.znode.parent\", \"/hbase-unsecure\")\n",
    "hbaseConf.set(\"hbase.cluster.distributed\", \"true\")\n",
    "\n",
    "val connection = ConnectionFactory.createConnection(hbaseConf)\n",
    "\n",
    "val table = connection.getTable(TableName.valueOf(\"nyse:stock_data_thick\"))\n",
    "\n",
    "val filter = new ColumnPrefixFilter(Bytes.toBytes(\"20160129\"))\n",
    "val scan = new Scan()\n",
    "scan.setFilter(filter)\n",
    "\n",
    "val scanner = table.getScanner(scan)\n",
    "var result = scanner.next()\n",
    "\n",
    "while (result != null) {\n",
    "  for(cell <- result.rawCells()) {\n",
    "    println(\"row key:\" + Bytes.toString(CellUtil.cloneRow(cell)) +\n",
    "      \":column family:\" + Bytes.toString(CellUtil.cloneFamily(cell)) +\n",
    "      \":column name:\" + Bytes.toString(CellUtil.cloneQualifier(cell)) +\n",
    "      \":value:\" + Bytes.toString(CellUtil.cloneValue(cell)))\n",
    "  }\n",
    "  result = scanner.next()\n",
    "}\n",
    "\n",
    "table.close\n",
    "connection.close"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
