{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Transformations\n",
    "\n",
    "## Overview of Basic Transformations\n",
    "\n",
    "We will cover filtering, aggregations and sorting as part of this module and look into joins and ranking in subsequent modules.\n",
    "\n",
    "Let us define problem statements and come up with solutions to learn more about Data Frame APIs. \n",
    "* Get total number of flights as well as number of flights which are delayed in departure and number of flights delayed in arrival. \n",
    " * Output should contain 3 columns - **FlightCount**, **DepDelayedCount**, **ArrDelayedCount**\n",
    "* Get number of flights which are delayed in departure and number of flights delayed in arrival for each day along with number of flights departed for each day. \n",
    " * Output should contain 4 columns - **FlightDate**, **FlightCount**, **DepDelayedCount**, **ArrDelayedCount**\n",
    " * **FlightDate** should be of **YYYY-MM-dd** format.\n",
    " * Data should be **sorted** in ascending order by **flightDate**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting Spark Context\n",
    "\n",
    "Let us start spark context for this Notebook so that we can execute the code provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession.\n",
    "    builder.\n",
    "    config(\"spark.ui.port\", \"0\").\n",
    "    appName(\"Basic Transformations\").\n",
    "    master(\"yarn\").\n",
    "    getOrCreate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Filtering\n",
    "Let us understand few important details related to filtering before we get into the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val airlines_path = \"/public/airlines_all/airlines-part/flightmonth=200801\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys.process._\n",
    "\n",
    "\"hdfs dfs -ls /public/airlines_all/airlines-part/flightmonth=200801\" !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val airlines = spark.\n",
    "    read.\n",
    "    parquet(airlines_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Filtering can be done either by using `filter` or `where`. These are like synonyms to each other.\n",
    "* When it comes to the condition, we can either pass it in **SQL Style** or **Data Frame Style**.\n",
    "* Example for SQL Style - `airlines.filter(\"IsArrDelayed = 'YES'\").show() or airlines.where(\"IsArrDelayed = 'YES'\").show()`\n",
    "* Example for Data Frame Style - `airlines.filter(airlines(\"IsArrDelayed\") === \"YES\").show()` or `airlines.filter($\"IsArrDelayed\" === \"YES\").show()`. We can also use where instead of filter.\n",
    "* Here are the other operations we can perform to filter the data - `!=`, `>`, `<`, `>=`, `<=`, `LIKE`, `BETWEEN` with `AND`\n",
    "* If we have to validate against multiple columns then we need to use boolean operations such as `AND` and `OR`.\n",
    "* If we have to compare each column value with multiple values then we can use the `IN` operator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "Let us perform some tasks to understand filtering in detail. Solve all the problems by passing  conditions using both SQL Style as well as API Style.\n",
    "\n",
    "* Read the data for the month of 2008 January."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "val airlines_path = \"/public/airlines_all/airlines-part/flightmonth=200801\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "val airlines_all = spark.\n",
    "    read.\n",
    "    parquet(airlines_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "airlines_all.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val airlines = airlines_all.\n",
    "    select(\"Year\", \"Month\", \"DayOfMonth\",\n",
    "           \"DepDelay\", \"ArrDelay\", \"UniqueCarrier\", \n",
    "           \"FlightNum\", \"IsArrDelayed\", \"IsDepDelayed\"\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get count of flights which are departed late at origin and reach destination early or on time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SQL Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.\n",
    "    filter(\"IsDepDelayed = 'YES' AND IsArrDelayed = 'NO'\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* API Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.\n",
    "    filter(col(\"IsDepDelayed\") === \"YES\" and col(\"IsArrDelayed\") === \"NO\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.\n",
    "    filter($\"IsDepDelayed\" === \"YES\" and $\"IsArrDelayed\" === \"NO\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.\n",
    "    filter(airlines(\"IsDepDelayed\") === \"YES\" and airlines(\"IsArrDelayed\") === \"NO\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get count of flights which are departed late from origin by more than 60 minutes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SQL Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.\n",
    "    filter(\"DepDelay > 60\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* API Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.\n",
    "    filter(col(\"DepDelay\") > 60).\n",
    "    count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.\n",
    "    filter($\"DepDelay\" > 60).\n",
    "    count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.\n",
    "    filter(airlines(\"DepDelay\") > 60).\n",
    "    count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get count of flights which are departed early or on time but arrive late by at least 15 minutes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SQL Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.\n",
    "    filter(\"IsDepDelayed = 'NO' AND ArrDelay >= 15\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* API Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.\n",
    "    filter(col(\"IsDepDelayed\") === \"NO\" and col(\"ArrDelay\") >= 15).\n",
    "    count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.\n",
    "    filter($\"IsDepDelayed\" === \"NO\" and $\"ArrDelay\" >= 15).\n",
    "    count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.\n",
    "    filter(airlines(\"IsDepDelayed\") === \"NO\" and airlines(\"ArrDelay\") >= 15).\n",
    "    count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get count of flights departed from following major airports - ORD, DFW, ATL, LAX, SFO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SQL Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines_all.\n",
    "    filter(\"Origin IN ('ORD', 'DFW', 'ATL', 'LAX', 'SFO')\").\n",
    "    select(\"Origin\").\n",
    "    distinct.\n",
    "    show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines_all.\n",
    "    filter(\"Origin IN ('ORD', 'DFW', 'ATL', 'LAX', 'SFO')\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* API Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines_all.\n",
    "    filter(col(\"Origin\") isin (\"ORD\", \"DFW\", \"ATL\", \"LAX\", \"SFO\")).\n",
    "    count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines_all.\n",
    "    filter($\"Origin\" isin (\"ORD\", \"DFW\", \"ATL\", \"LAX\", \"SFO\")).\n",
    "    count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines_all.\n",
    "    filter(airlines_all(\"Origin\") isin (\"ORD\", \"DFW\", \"ATL\", \"LAX\", \"SFO\")).\n",
    "    count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get count of flights departed late between 2008 January 1st to January 9th using FlightDate.\n",
    "* Date should be of `yyyyMMdd` format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Add a column FlightDate by using Year, Month and DayOfMonth. Format should be `yyyyMMdd`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{lpad, concat, col}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.\n",
    "    withColumn(\"FlightDate\", \n",
    "               concat(col(\"Year\"), \n",
    "                      lpad(col(\"Month\"), 2, \"0\"), \n",
    "                      lpad(col(\"DayOfMOnth\"), 2, \"0\")\n",
    "                     )\n",
    "              ).\n",
    "    show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SQL Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.\n",
    "    withColumn(\"FlightDate\", \n",
    "               concat(col(\"Year\"), \n",
    "                      lpad(col(\"Month\"), 2, \"0\"), \n",
    "                      lpad(col(\"DayOfMOnth\"), 2, \"0\")\n",
    "                     )\n",
    "              ).\n",
    "    filter(\"FlightDate LIKE '2008010%' AND IsDepDelayed = 'YES'\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.\n",
    "    withColumn(\"FlightDate\", \n",
    "               concat(col(\"Year\"), \n",
    "                      lpad(col(\"Month\"), 2, \"0\"), \n",
    "                      lpad(col(\"DayOfMOnth\"), 2, \"0\")\n",
    "                     )\n",
    "              ).\n",
    "    filter(\"FlightDate BETWEEN '20080101' AND '20080109' AND IsDepDelayed = 'YES'\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* API Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.\n",
    "    withColumn(\"FlightDate\", \n",
    "               concat(col(\"Year\"), \n",
    "                      lpad(col(\"Month\"), 2, \"0\"), \n",
    "                      lpad(col(\"DayOfMOnth\"), 2, \"0\")\n",
    "                     )\n",
    "              ).\n",
    "    filter($\"FlightDate\" like \"2008010%\" and $\"IsDepDelayed\" === \"YES\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.\n",
    "    withColumn(\"FlightDate\", \n",
    "               concat(col(\"Year\"), \n",
    "                      lpad(col(\"Month\"), 2, \"0\"), \n",
    "                      lpad(col(\"DayOfMOnth\"), 2, \"0\")\n",
    "                     )\n",
    "              ).\n",
    "    filter($\"FlightDate\" between (\"20080101\", \"20080109\") and $\"IsDepDelayed\" === \"YES\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get number of flights departed late on Sundays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val l = List(\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val df = l.toDF(\"dummy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.current_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(current_date).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(current_date, date_format(current_date, \"EEEE\")).show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SQL Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.\n",
    "    withColumn(\"FlightDate\", \n",
    "               concat(col(\"Year\"), \n",
    "                      lpad(col(\"Month\"), 2, \"0\"), \n",
    "                      lpad(col(\"DayOfMOnth\"), 2, \"0\")\n",
    "                     )\n",
    "              ).\n",
    "    filter(\"date_format(to_date(FlightDate, 'yyyyMMdd'), 'EEEE') = 'Sunday' AND IsDepDelayed = 'YES'\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* API Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.\n",
    "    withColumn(\"FlightDate\", \n",
    "               concat(col(\"Year\"), \n",
    "                      lpad(col(\"Month\"), 2, \"0\"), \n",
    "                      lpad(col(\"DayOfMOnth\"), 2, \"0\")\n",
    "                     )\n",
    "              ).\n",
    "    filter(date_format(to_date($\"FlightDate\", \"yyyyMMdd\"), \"EEEE\") === \"Sunday\" and $\"IsDepDelayed\" === \"YES\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Aggregations\n",
    "\n",
    "Let us go through the details related to aggregations using Spark.\n",
    "\n",
    "* We can perform total aggregations directly on Dataframe or we can perform aggregations after grouping by a key(s).\n",
    "* Here are the APIs which we typically use to group the data using a key.\n",
    " * `groupBy`\n",
    " * `rollup`\n",
    " * `cube`\n",
    "* Here are the functions which we typically use to perform aggregations.\n",
    " * `count`\n",
    " * `sum`, `avg`\n",
    " * `min`, `max`\n",
    "* If we want to provide aliases to the aggregated fields then we have to use `agg` after `groupBy`.\n",
    "* Let us get the count of flights for each day for the month of 200801."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val airlines_path = \"/public/airlines_all/airlines-part/flightmonth=200801\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val airlines = spark.\n",
    "    read.\n",
    "    parquet(airlines_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{lpad, concat, count, lit}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.\n",
    "    groupBy(concat(\n",
    "        $\"Year\", \n",
    "        lpad($\"Month\", 2, \"0\"), \n",
    "        lpad($\"DayOfMonth\", 2, \"0\")).alias(\"FlightDate\")\n",
    "    ).\n",
    "    agg(count(lit(1)).alias(\"FlightCount\")).\n",
    "    show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Sorting\n",
    "\n",
    "Let us understand how to sort the data in a Data Frame.\n",
    "* We can use `orderBy` or `sort` to sort the data.\n",
    "* We can perform composite sorting by passing multiple columns or expressions.\n",
    "* By default data is sorted in ascending order, we can change it to descending by applying `desc()` function on the column or expression.\n",
    "* Let us sort the Flight Count for each day for the month of 2008 January in descending order by count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val flightCountDaily = airlines.\n",
    "    groupBy(concat(\n",
    "        $\"Year\", \n",
    "        lpad($\"Month\", 2, \"0\"), \n",
    "        lpad($\"DayOfMonth\", 2, \"0\")).alias(\"FlightDate\")\n",
    "    ).\n",
    "    agg(count(lit(1)).alias(\"FlightCount\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flightCountDaily.orderBy($\"FlightCount\".desc).show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions - Problem 1\n",
    "Get total number of flights as well as number of flights which are delayed in departure and number of flights delayed in arrival. \n",
    "* Output should contain 3 columns - **FlightCount**, **DepDelayedCount**, **ArrDelayedCount**\n",
    "\n",
    "### Reading airlines data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "val airlines_path = \"/public/airlines_all/airlines-part/flightmonth=200801\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "val airlines_all = spark.\n",
    "    read.\n",
    "    parquet(airlines_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val airlines = airlines_all.\n",
    "    select(\"Year\", \"Month\", \"DayOfMonth\",\n",
    "           \"DepDelay\", \"ArrDelay\", \"UniqueCarrier\", \n",
    "           \"FlightNum\", \"IsArrDelayed\", \"IsDepDelayed\"\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "airlines.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get flights with delayed arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//SQL Style\n",
    "airlines.filter(\"IsArrDelayed = 'YES'\").show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// API Style\n",
    "airlines.filter(airlines(\"IsArrDelayed\") === \"YES\").show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.filter(col(\"IsArrDelayed\") === \"YES\").show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.filter($\"IsArrDelayed\" === \"YES\").show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get delayed counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Departure Delayed Count\n",
    "airlines.\n",
    "    filter(airlines(\"IsDepDelayed\") === \"YES\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Arrival Delayed Count\n",
    "airlines.\n",
    "    filter(airlines(\"IsArrDelayed\") === \"YES\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{col, lit, count, sum, expr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.agg(count(lit(1)).alias(\"FlightCount\"),\n",
    "             sum(expr(\"CASE WHEN IsDepDelayed = 'YES' THEN 1 ELSE 0 END\")).alias(\"DepDelayedCount\"),\n",
    "             sum(expr(\"CASE WHEN IsArrDelayed = 'YES' THEN 1 ELSE 0 END\")).alias(\"ArrDelayedCount\")\n",
    "            ).show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Solutions - Problem 2\n",
    "\n",
    "Get number of flights which are delayed in departure and number of flights delayed in arrival for each day along with number of flights departed for each day. \n",
    "\n",
    "* Output should contain 4 columns - **FlightDate**, **FlightCount**, **DepDelayedCount**, **ArrDelayedCount**\n",
    "* **FlightDate** should be of **yyyy-MM-dd** format.\n",
    "*   Data should be **sorted** in ascending order by **flightDate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "val airlines_path = \"/public/airlines_all/airlines-part/flightmonth=200801\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "val airlines_all = spark.\n",
    "    read.\n",
    "    parquet(airlines_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val airlines = airlines_all.\n",
    "    select(\"Year\", \"Month\", \"DayOfMonth\",\n",
    "           \"DepDelay\", \"ArrDelay\", \"UniqueCarrier\", \n",
    "           \"FlightNum\", \"IsArrDelayed\", \"IsDepDelayed\"\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "airlines.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Grouping Data by Flight Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{lit, col, lpad, concat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.\n",
    "    groupBy(concat($\"Year\", \n",
    "                   lit(\"-\"),\n",
    "                   lpad($\"Month\", 2, \"0\"), \n",
    "                   lit(\"-\"),\n",
    "                   lpad($\"DayOfMonth\", 2, \"0\")\n",
    "                  )\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Counts by Flight Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.\n",
    "    groupBy(concat($\"Year\", \n",
    "                   lit(\"-\"),\n",
    "                   lpad($\"Month\", 2, \"0\"), \n",
    "                   lit(\"-\"),\n",
    "                   lpad($\"DayOfMonth\", 2, \"0\")\n",
    "                  ).alias(\"FlightDate\")\n",
    "           ).\n",
    "    count.\n",
    "    show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.\n",
    "    filter(\"IsDepDelayed = 'YES'\").\n",
    "    groupBy(concat($\"Year\", \n",
    "                   lit(\"-\"),\n",
    "                   lpad($\"Month\", 2, \"0\"), \n",
    "                   lit(\"-\"),\n",
    "                   lpad($\"DayOfMonth\", 2, \"0\")\n",
    "                  ).alias(\"FlightDate\")\n",
    "           ).\n",
    "    count.\n",
    "    show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.\n",
    "    filter(\"IsArrDelayed = 'YES'\").\n",
    "    groupBy(concat($\"Year\", \n",
    "                   lit(\"-\"),\n",
    "                   lpad($\"Month\", 2, \"0\"), \n",
    "                   lit(\"-\"),\n",
    "                   lpad($\"DayOfMonth\", 2, \"0\")\n",
    "                  ).alias(\"FlightDate\")\n",
    "           ).\n",
    "    count.\n",
    "    show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting total as well as delayed counts for each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{sum, count, expr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.\n",
    "    groupBy(concat($\"Year\", \n",
    "                   lit(\"-\"),\n",
    "                   lpad($\"Month\", 2, \"0\"), \n",
    "                   lit(\"-\"),\n",
    "                   lpad($\"DayOfMonth\", 2, \"0\")\n",
    "                  ).alias(\"FlightDate\")\n",
    "           ).\n",
    "    agg(count(lit(1)).alias(\"FlightCount\"),\n",
    "        sum(expr(\"CASE WHEN IsDepDelayed = 'YES' THEN 1 ELSE 0 END\")).alias(\"DepDelayedCount\"),\n",
    "        sum(expr(\"CASE WHEN IsArrDelayed = 'YES' THEN 1 ELSE 0 END\")).alias(\"ArrDelayedCount\")\n",
    "       ).\n",
    "    show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting Data By FlightDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.\n",
    "    groupBy(concat($\"Year\", \n",
    "                   lit(\"-\"),\n",
    "                   lpad($\"Month\", 2, \"0\"), \n",
    "                   lit(\"-\"),\n",
    "                   lpad($\"DayOfMonth\", 2, \"0\")\n",
    "                  ).alias(\"FlightDate\")\n",
    "           ).\n",
    "    agg(count(lit(1)).alias(\"FlightCount\"),\n",
    "        sum(expr(\"CASE WHEN IsDepDelayed = 'YES' THEN 1 ELSE 0 END\")).alias(\"DepDelayedCount\"),\n",
    "        sum(expr(\"CASE WHEN IsArrDelayed = 'YES' THEN 1 ELSE 0 END\")).alias(\"ArrDelayedCount\")\n",
    "       ).\n",
    "    orderBy(\"FlightDate\").\n",
    "    show(31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "\n",
     "\n",
     "\n"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
